---
title: "Practice Data Wrangling"
author: "Sophie"
date: "12/01/2020"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```
## Importing data
## Import a .csv from your computer
```{r}
#method1: data1 <- read.csv(file.choose(), header=T)
setwd("~/Desktop/2309/W2")
data1 <- read.csv("zoo.csv", header = T)
```
## Import a .csv file from online
```{r}
#header=true: the first row is the name of the column
babynames = read.csv("https://data.cityofnewyork.us/api/views/25th-nujf/rows.csv", header=TRUE, sep=',', stringsAsFactors = FALSE )
```
Note that the default for the seprator is ',' change it as needed

## Data Preparation
For data to be tidy, each row must have one observation 
## Create dataframes through binding columns
Use rep to create a column of the following values and call it animal (for farm animals)
{"MO", "MO", "MO", "MO", "LN", "SE", "QM"}
Create vectors "length" {11, 7, 7, 12, 9, 9, 11} and "TB" {0, 0, 1, 1, 0, 0, 0} to indicate tubercolisis in farm animals
```{r}
animal <- rep(c("MO", "LN", "SE", "QM"), c(4, 1, 1, 1))
length <- c(11, 7, 7, 15, 9, 12, 11)
TB <- c( 0, 0, 1, 1, 0, 0, 0)
```

Use cbind to create a dataframe "Farm" for farm animals. rbind gathers rows rather than columns
```{r}
# cbind for binding colunm, and rbind for binding rows
#data frame is look like a table
Farm <- cbind(animal,length, TB)
class(Farm)  ## produces a matrix
Farm <- cbind.data.frame(animal,length, TB) # to bind columns as a dataframe
class(Farm)
Farm     
```
##Import a dataset from tidyverse
```{r}
install.packages("tidyverse")
install.packages("dslabs")
library(tidyverse) 
library(dslabs)
path <- system.file("extdata", package="dslabs")
filename <- file.path(path, "fertility-two-countries-example.csv")
wide_data <- read_csv(filename)  ## data on fertility rate in Germany and S.Korea over the years
head(wide_data)
```
### MANIPULATING DATA FRAMES
## Add a column with "mutate"
The function mutate takes the data frame as a first argument and the name and values of 
the variable as a second argument using the convention name = values
ex: add a column rate of crime per 100000 to the "murders" dataset in library dslabs
```{r}
library(tidyverse) 
library(dslabs)
data("murders")
colnames(murders)
murders <- mutate(murders, rate = total / population * 100000)
head(murders)
```


## Subsetting with filter
Filter the data table to only show the entries for which the murder rate is lower than 0.71
```{r}
filter(murders, rate <= 0.71)
```

## Selecting columns with select
```{r}
new_table <- select(murders, state, region, rate)
filter(new_table, rate <= 0.71)
```

###EXERCISES 1###
Load the dplyr and dslabs packages and load the murders dataset
1. Use the function mutate to add a murders column named rate with the per 100,000 murder rate
```{r}
library(tidyverse)
library(dslabs)
data("murders")
murders<-mutate(murders, rate= total /population * 100000)
```


2. If rank(x) gives you the ranks of x from lowest to highest, rank(-x) gives you the ranks from highest to lowest. Use the function mutate to add a column rank containing the rank, from highest to lowest murder rate. Make sure you redefine/overwrite murders so we can keep using this variable. Show the head of murders.
```{r}
murders<-mutate(murders, rank=rank(-rate))
head(murders)
```


#3. Use select to show the state names and abbreviations in murders. Do not redefine murders, just show the results.
```{r}
select(murders, state, abb)
```


4. The dplyr function filter is used to choose specific rows of the data frame to keep. 
Unlike select which is for columns, filter is for rows. 
For example, you can show just the New York row like this: filter(murders, state == "New York")
You can use other logical vectors to filter rows.

Use filter to show the top 5 states with the highest murder rates. 
After we add murder rate and rank, do not change the murders dataset, just show the result. Remember that you can filter based on the rank column.
```{r}
filter(murders, rank>=47)
```


5. We can remove rows using the != operator. For example, to remove Florida, we would do this: no_florida <- filter(murders, state != "Florida")

Create a new data frame called no_south that removes states from the South region. 
How many states are in this category? You can use the function nrow for this.
```{r}
no_south<-filter(murders, region!="South")
nrow(no_south)
```

6. We can also use %in% to filter with dplyr. 
You can therefore see the data from New York and Texas like this:
  
filter(murders, state %in% c("New York", "Texas"))

Create a new data frame called murders_nw with only the states from the Northeast or the West. How many states are in this category?
```{r}
murders_nw<-filter(murders, region%in% c("Northeast", "West"))
nrow(murders_nw)
```

  
7. Suppose you want to live in the Northeast or West and want the murder rate to be less than 1. 
We want to see the data for the states satisfying these options. 
Note that you can use logical operators with filter. Here is an example in which we filter to keep only small states in the Northeast region.

filter(murders, population < 5000000 & region == "Northeast")
Make sure murders has been defined with rate and rank and still has all states. 
Create a table called my_states that contains rows for states satisfying 
both the conditions: it is in the Northeast or West and the murder rate is less than 1. 
Use select to show only the state name, the rate, and the rank.
```{r}
my_states<-filter(murders, region%in% c("Northeast", "West") & rate<1)
my_states2<-filter(murders_nw,rate<1) #another way to do it
identical(my_states, my_states2)
select(my_states, state)
select(my_states, state, rate, rank)
```


###### Remove columns or rows from a dataframe
Read the column names of the murders dataset
```{r}
data("murders")
colnames(murders)
```

### Remove the state abbreviation column
```{r}
murders <- murders[,-2]
colnames(murders)
```

### Remove the 2nd and 3rd row of murders
```{r}
nrow(murders)  ## check number of rows before removing the 2 rows
murders <- murders[-c(2,3),]
nrow(murders)
```
   

### SORTING DATA
## Sorting vectors using Sort and Order
```{r}
sort(murders$total)  ## ascending order
sort(murders$total, decreasing = T)  #descending order
max(murders$total)
min(murders$total)
```


```{r}
order(murders$total)
which.max(murders$total)
murders$state[which.max(murders$total)]
which.min(murders$total)
murders$state[which.min(murders$total)]
```
The output shows that the state with least murders$total is at position 46 (Vermont) and the one with the most is at position 5 (california)

What is the difference between sort and order?
Sort puts a vector in increasing order, order gives the index of the order.


## Sorting dataframes
## Use arrange to sort the dataframe based on a certain vector

```{r}
arrange(murders,desc(population))  # sort data frame in descending order of population
arrange(murders, region, total) # sort regions, then within each region by total
```

#########
#ERRONEOUS DATA
Data exploration
Download the zoo dataset from Quercus and read it from the folder you saved it in
Explore zoo
```{r}
#zoo <- read.csv(file.choose(), header=T)
setwd("~/Desktop/2309/W2")
zoo <- read.csv("zoo.csv", header = T)
str(zoo)   ## tells about classes 
summary(zoo)  ## tells about distribution inside each column
```
Hair should be either 1 or 0
Create a subset of erroneous variables not 1,0 as expected
```{r}
D2 <- subset(zoo, !(zoo$Hair %in% c(1,0)))#can find the location  
D4 <- filter(zoo, !(zoo$Hair %in% c(1,0)))  ##gives no row number

D2  #hair has a question mark
D3 <- which(!(zoo$Hair %in% c(1,0)))  ## this is its location (on row 65)
D3
```

##Remove unwanted extra characters
```{r}
head(zoo$Name)
class(zoo$Name)
zoo$Name <- gsub(",", "", zoo$Name)   ## removes all commas and substitute with nothing
head(zoo$Name)
class(zoo$Name)  ## this action transforms the column into character
zoo$Name <- as.factor(zoo$Name) ## to return it to factor
```


#######EXERCISES 2 on SORTING AND ERRONEOUS DATA

1. Import the healthraw dataset from week2 on Quercus
```{r}
#healthraw <- read.csv(file.choose(), header=T)  ##choose healthraw.csv
setwd("~/Desktop/2309/W2")
healthraw <- read.csv("healthraw.csv", header = T)
```

2. Remove the first column X of healthraw dataset and save the results in health_cleaned dataset
```{r}
health_cleaned<-healthraw[,-1]
```

3. check the levels of the column Gender in health_cleaned
```{r}
levels(health_cleaned$Gender)
```

4. use subset to create a subset of the erroneous rows in Gender
Display the head of the subset
```{r}
error_gender <- subset(health_cleaned, !(health_cleaned$Gender %in% c("Female","Male") ))
head(error_gender)
```

5. Identify the positions of the errors
```{r}
error_position<-which(!(health_cleaned$Gender %in% c("Female", "Male")))
error_position
```

6. Fix the errors in column Gender
```{r}
health_cleaned$Gender[70]#check the value of the erroneous data
health_cleaned$Gender[70]<-"Female"  ##Fix it
health_cleaned$Gender[83]#check the value of the erroneous data
health_cleaned$Gender[83]<-"Male"
```

7.  check for any errors in column SystolicBP in the health_cleaned dataset, get its position and fix it
Hint: explore the summary of the column and guess where the error could be
```{r}
summary(health_cleaned$SystolicBP)   ##looks like the max value 1405 is a problem, should be 140.5
which(health_cleaned$SystolicBP==1405)  # find its position
health_cleaned$SystolicBP[100] <- 140.5  ## fix it  
```


8. Sort health_cleaned based on SystolicBP in descending order, just display the results and don't create a new variable
```{r}
arrange(health_cleaned,desc(SystolicBP))
```

################################################
##MISISNG VALUES
## Identify missing values
```{r}
x = c(1, 2, 3, NA)
mean(x)
mean(x, na.rm=TRUE) #rm means remove
sum(x)
sum(na.omit(x))  ## sum of all values except NA
sum(!is.na(x))  ## count of the values that are not NA
#sum(is.na(x))
y <- na.omit(x)
length(y)
```
##Recode 999 to missing (NA)
# remap values of x with missing value code of 999 to missing
```{r}
#easier way
w <- c(1, 2, 999)
w[w==999] <- NA
w
#another way
w <- c(1,2,999)
is.na(w) <- w==999 # set 999's to missing
w
```

###Missing values in data frames
read online dataset
```{r}
ds <- read.csv("http://www.amherst.edu/~nhorton/r2/datasets/helpmiss.csv")
smallds <- with(ds, data.frame(i1, sexrisk, indtot, mcs, pcs))
```

```{r}
sum(is.na(smallds))    ## check number of missing in the whole dataframe (19 mising cells)
sapply(smallds, function(x) sum(is.na(x))) ##check number of missing in each column
```

## Handling missing data
##I. Remove all rows with missing data
```{r}
smallds_missingRemoved <- na.omit(smallds)
sum(is.na(smallds_missingRemoved))
```

Identify records with missing values in more than one column
Create a dataframe A1 having missing variables in more than one column
```{r}
A1 <- data.frame(i1=c(NA,1,0,4), sexrisk=c(1,0,NA,NA), indtot=c(NA,40,35,NA), mcs=c(NA,32,NA,NA), pcs=c(50,58,NA,NA))
smallds_missing <- rbind(A1, smallds)  ## 4 rows of A1 added
smallds_missing
```

Identify rows with 3 missing values
```{r}
missing_3 <- smallds_missing[rowSums(is.na(smallds_missing))==3,]
nrow(missing_3)  ## length=2 cases, why not 3 cases?
```

Remove missing values related to a certain column, use original dataset "smallds"
```{r}
sum(is.na(smallds$mcs))   # 2 values are missing in mcs
missing_mcs <- which(is.na(smallds$mcs))  ## identify their position
smallds_mcs_missing_removed <- smallds[-missing_mcs,] #two rows removed
nrow(smallds)
nrow(smallds_mcs_missing_removed)
```

## II. Single imputation 
Consider marks of students in math are {88, 95, 85, NA, 76, 69, 78, NA, 70, 68}
Create a vector of these marks and call it Math
Impute the missing values with the mean and store in a new vector called Math1
```{r}
Math <- c(88, 95, 85, NA, 76, 69, 78, NA, 70, 68)
meanvalue <- mean(Math, na.rm=TRUE)
meanvalue
Math1 <- Math
Math1[is.na(Math1)] <- meanvalue
Math1
```

### EXERCISES 3 on MISSING DATA 
Create the heahealth_cleaned dataset through running the following code
```{r}
#healthraw <- read.csv(file.choose(), header=T)
setwd("~/Desktop/2309/W2")
healthraw <- read.csv("healthraw.csv", header = T)
health_cleaned <- healthraw[,-1]
```

1. Check  if there is missing data in all the health_cleaned dataset then display number of missing in each column

```{r}
sum(is.na(health_cleaned))
sapply(health_cleaned, function(x) sum(is.na(x)))
```
  
2. Copy health_cleaned in a new variable called temp and use na.omit to remove all mising values from temp
```{r}
temp<-health_cleaned
temp<-na.omit(temp)
sum(is.na(temp))
```

##3. copy health_cleaned in a new variable called single and impute the missing values in the column age with the mean of age
```{r}
single<-health_cleaned
meanvalue<-mean(single$Age,na.rm=T)
single$Age[is.na(single$Age)]<-meanvalue
sum(is.na(single$Age))
```

### Data Transformations
## Normalization
Import the cars dataset in R and explore it using smmary
```{r}
mydata <- cars   
summary(cars) 
```
speed and dist are of different scale, range of speed and distance are very different

##create a function to normalize data
```{r}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}
```

## Apply the function to the 2 columns
```{r}
mydata$speed_norm<-normalize(mydata$speed)
mydata$dist_norm<-normalize(mydata$dist)
head(mydata)
```

## EXERCISES 4 on NORMALIZATION AND STANDARDIZATION
## Create a function "standardize" that will standardize data. Apply it for the cars dataset and display the head of the dataset
## tip: look at lecture notes p.20 for the formula of standardization
```{r}
standardize <- function(x) {
  return ((x - mean(x)) / sd(x))
}
mydata$speed_std<-standardize(mydata$speed)
mydata$dist_std<-standardize(mydata$dist)
head(mydata)
```

##III. Multiple imputation  (OPTIONAL)
#Multivariate Imputation via Chained Equations (MICE)
```{r}
#install.packages("mice")  
library(mice)
summary(smallds)  #tells which columns have NAs
colnames(smallds)
```
```{r}
```

##There are 14 rows missing "indtot", 2 missing mcs and pcs, and 1 missing sexrisk.
```{r}
library(mice)
md.pattern(smallds)
```

How to read the table: 
Horizontally:
454 with no missing values, 13 with missing values in indtot, 
2 with missing in mcs and pcs
and 1 with missing values in sexrisk and indtot
VerticallL
also i1 has no missing, sexrisk has 1, mcs has 2, pcs has 2 and indtot has 14.

# visualize the missing in a better way
```{r}
#install.packages("VIM")
library(VIM)
missing_plot <- aggr(smallds, col=c('navyblue','yellow'),
                    numbers=TRUE, sortVars=TRUE,
                    labels=names(smallds), cex.axis=.7, cex.numbers=0.3,
                    gap=0.1, ylab=c("Missing data","Pattern"))
```

In the written output, we get % of missing in each variable ex: 2.98% for indtot
In the visualization, you get the graph of the histogram of counts and the pattern, ex: 96% complete data
2.77% missing indtot alone, etc. 
Also from the output, number of missing in indtot is 0.029 of all data (14/470=0.029) 

# Methods used by mice to impute missing
PMM (Predictive Mean Matching)  – For numeric variables
logreg(Logistic Regression) – For Binary Variables( with 2 levels)
polyreg(Bayesian polytomous regression) – For Factor Variables (>= 2 levels)
Proportional odds model (ordered, >= 2 levels)

```{r}
imputed_Data <- mice(smallds, m=5, maxit = 50, method = 'pmm', seed = 500)
summary(imputed_Data)
```

m  – Refers to 5 imputed data sets
maxit – Refers to no. of iterations taken to impute missing values
method – Refers to method used in imputation. we used predictive mean matching.
This produces 5 different imputed complete datasets

check imputed values for indtot and get a list of 14 imputed missing for 5 different complete datasets
```{r}
imputed_Data$imp$indtot  
```


Get complete data2 ( 2nd out of 5) You can select any of the 5 complete datasets created
```{r}
completeData2 <- complete(imputed_Data,2)
head(completeData2)
mean2 <- mean(completeData2$sexrisk)
```
Do the same for the four other datasets and take the mean of the five means as the value of imputation for the missing 






